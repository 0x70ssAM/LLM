# Model to use
OLLAMA_MODEL=gpt-oss

# The Ollama API as seen FROM the container.
# Because Ollama is on the same host, we use Docker's host-gateway name.
# Make sure the Ollama service is bound to 0.0.0.0:11434 or your host IP.
#OLLAMA_IP=$(curl -s https://api.ipify.org)
#if [ -z "$OLLAMA_IP" ]; then
#    echo "Error: Unable to retrieve public IP."
#    exit 1
#fi
OLLAMA_IP=127.0.0.1

OLLAMA_URL="http://$OLLAMA_IP:11434"

# Defaults
OLLAMA_DEFAULT_PROMPT=Hello, how can I assist you today?
OLLAMA_CONNECTION_TIMEOUT=30

# Web server bind (inside container)
APP_HOST=0.0.0.0
APP_PORT=8080
